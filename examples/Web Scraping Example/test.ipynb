{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ted.ng/Desktop/DA/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.usinflationcalculator.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2023', '299.170', '300.840', '301.836', '303.363', '304.127', '305.109', '305.691', '307.026', '307.789', '307.671', '307.051', '306.746', '304.702', '3.4', '4.1', ''], ['2024', '308.417', '310.326', '312.332', '313.548', '314.069', '314.175', '314.540', '314.796', '315.301', 'Avail.Nov. 13', '', '', '', '', '', '']]\n",
      "['1992', '138.1', '138.6', '139.3', '139.5', '139.7', '140.2', '140.5', '140.9', '141.3', '141.8', '142.0', '141.9', '140.3', '2.9', '3.0']\n",
      "   Year   Jan   Feb   Mar   Apr   May  June  July   Aug   Sep   Oct   Nov  \\\n",
      "0  1913   9.8   9.8   9.8   9.8   9.7   9.8   9.9   9.9  10.0  10.0  10.1   \n",
      "1  1914  10.0   9.9   9.9   9.8   9.9   9.9  10.0  10.2  10.2  10.1  10.2   \n",
      "2  1915  10.1  10.0   9.9  10.0  10.1  10.1  10.1  10.1  10.1  10.2  10.3   \n",
      "3  1916  10.4  10.4  10.5  10.6  10.7  10.8  10.8  10.9  11.1  11.3  11.5   \n",
      "4  1917  11.7  12.0  12.0  12.6  12.8  13.0  12.8  13.0  13.3  13.5  13.5   \n",
      "\n",
      "    Dec   Avg Dec-Dec Avg-Avg  \n",
      "0  10.0   9.9       –       –  \n",
      "1  10.1  10.0     1.0     1.0  \n",
      "2  10.3  10.1     2.0     1.0  \n",
      "3  11.6  10.9    12.6     7.9  \n",
      "4  13.7  12.8    18.1    17.4  \n",
      "     Year      Jan      Feb      Mar      Apr      May     June     July  \\\n",
      "105  2018  247.867  248.991  249.554  250.546  251.588  251.989  252.006   \n",
      "106  2019  251.712  252.776  254.202  255.548  256.092  256.143  256.571   \n",
      "107  2020  257.971  258.678  258.115  256.389  256.394  257.797  259.101   \n",
      "108  2021  261.582  263.014  264.877  267.054  269.195  271.696  273.003   \n",
      "109  2022  281.148  283.716  287.504  289.109  292.296  296.311  296.276   \n",
      "\n",
      "         Aug      Sep      Oct      Nov      Dec      Avg Dec-Dec Avg-Avg  \n",
      "105  252.146  252.439  252.885  252.038  251.233  251.107     1.9     2.4  \n",
      "106  256.558  256.759  257.346  257.208  256.974  255.657     2.3     1.8  \n",
      "107  259.918  260.280  260.388  260.229  260.474  258.811     1.4     1.2  \n",
      "108  273.567  274.310  276.589  277.948  278.802  270.970     7.0     4.7  \n",
      "109  296.171  296.808  298.012  297.711  296.797  292.655     6.5     8.0  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the page with the table\n",
    "#url = 'https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)'\n",
    "url = \"https://www.usinflationcalculator.com/inflation/consumer-price-index-and-annual-percent-changes-from-1913-to-2008/\"\n",
    "\n",
    "# Send a GET request to the page\n",
    "response = requests.get(url, verify=False)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the page content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    #print(soup.prettify())\n",
    "\n",
    "    # Find the table with GDP data (the table is under the class \"wikitable\")\n",
    "    table = soup.find('table')\n",
    "    #print(table)\n",
    "\n",
    "    # Extract table headers\n",
    "    headers = []\n",
    "    #headers = [header.text.strip() for header in table.find_all('th')]\n",
    "\n",
    "    ##\n",
    "    #ValueError: 10 columns passed, passed data had 7 columns\n",
    "    ##\n",
    "    for header in table.find_all('th'):\n",
    "        colspan = int(header.get('colspan', 1))\n",
    "        if colspan == 1:\n",
    "            headers.append(header.text.strip())\n",
    "\n",
    "    #print(\"Headers:\", headers)\n",
    "\n",
    "\n",
    "    # Extract table rows\n",
    "    rows = table.find_all('tr')[1:]  # Skip the header row\n",
    "\n",
    "    # Initialize lists to hold row data\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        #print(\"len(row):\", len(row))\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) > 0:\n",
    "            row_data = [cell.text.strip() for cell in cells]\n",
    "            #print(len(row_data))\n",
    "            #print(\"Row data:\", row_data)\n",
    "            data.append(row_data)\n",
    "         \n",
    "    #print(data)\n",
    "    #print(data[0])\n",
    "    data_cleaned = [row for row in data if len(row) == len(data[0])]\n",
    "    rows_with_fewer_columns = [row for row in data if len(row) != len(data[0])]\n",
    "\n",
    "    #rows_with_fewer_columns = [i for i, row in enumerate(data) if len(row) != len(data[0])]\n",
    "\n",
    "    print(rows_with_fewer_columns)\n",
    "    print(data[80])\n",
    "# Convert to DataFrame\n",
    "    df = pd.DataFrame(data_cleaned[1:], columns=data_cleaned[0])\n",
    "    # Create a DataFrame from the data\n",
    "    #df = pd.DataFrame(data[0], columns=headers)\n",
    "    #df = pd.DataFrame(data[1:], columns=data[0])\n",
    "    \n",
    "    # Print the DataFrame\n",
    "    print(df.head())\n",
    "    print(df.tail())\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv('gdp_data.csv', index=False)\n",
    "    \n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [404]>\n",
      "404\n"
     ]
    }
   ],
   "source": [
    "url = \"https://charlieojackson.co.uk/tutor/JS/tests/test.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response)\n",
    "print(response.status_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
